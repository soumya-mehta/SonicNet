# SonicNet
Deep Learning for Dynamic Sound Classification using CNN


Performing Sound Recognition and Classification in Python necessitates audio files formatted for Deep Learning algorithms. This project focuses on processing sound signals via Mel-Frequency Cepstral Coefficients (MFCC) algorithms, readying audio for deep learning applications. Gain insights into preparing and processing a custom audio dataset for Deep Learning Training and Test operations. Construct a CNN (Convolutional Neural Network) Architecture with three Hidden Layers, totaling 500 neurons (125-250-125) utilizing TensorFlow and Keras libraries. Employ pre-processed sound signals from a previous project, featuring a dataset totaling 5.8 GB of audio.
